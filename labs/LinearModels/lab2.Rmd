---
title: "Multiple linear regression Lab using rethinking"
author:
 - "Andrea Sánchez-Tapia"
 - "Paulo Inácio Prado"
 - "Sara Mortara"
 - "Diogo Melo" 
date: "2025-01-28"
output:
    distill::distill_article:
      toc: true
      toc_depth: 3
---

```{r setup, echo=FALSE}
library(rmarkdown)
knitr::opts_chunk$set(eval = FALSE, fig.asp = 1)
library(rethinking)
```

# Introduction

We can extend the simple linear regression model to accommodate multiple predictors. These are the **multiple linear regression** models, of which the simple linear regression is just a particular case with a single predictor variable.

In the next sections, we will show how to fit multiple regression models using the `rethinking` package, interpret the model coefficients, and visualize the results.

# Additive multiple linear model

In an additive multiple linear regression, the expected value of the response $μ$ is the sum of multiple predictor variables $X_i$, each one weighted by its own coefficient $β_i$ :

$$
\begin{align}
y_i &\sim Normal(\mu_i, \sigma) \\
\mu_i & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \dots + \beta_j x_{ij} \\
\end{align}
$$


## Fitting

We will use the same dataset of the biennial plant *Ipomopsis aggregata*. Forty plants were assigned to two treatments: unprotected from grazing and protected from grazing. The fruit yield of each plant was measured along with the diameter of the rootstock.

Prepare the data:

```{r data, eval=TRUE}
df <- read.csv("https://raw.githubusercontent.com/lmmx/crawley-r-statistics-book-notes/master/code/ipomopsis.csv")
names(df) <- c("Root", "Fruit", "Grazing")
df$Root <- scale(df$Root, center = TRUE, scale = TRUE)
df$Fruit <- scale(df$Fruit, center = TRUE, scale = TRUE)

# Ungrazed is the control, and fenced grazed is the fenced treatment:
df$Grazing0 <- ifelse(df$Grazing == "Ungrazed", 1, 0)
```

Fit the additive model using `rethinking`:

```{r fit_model}
# Fitting the model using quap
m1 <- ulam(
  alist(
    Fruit ~ dnorm(mu, sigma),
    mu <- a + b * Grazing0 + c * Root,
    a ~ normal(0, 1),  
    b ~ normal(0, 1),   
    c ~ dnorm(0, 1),  
    sigma ~ exponential(1)          
  ),
  data = df, chains = 4, cores = 4
)
```

Extract and summarize the coefficients:

```{r summarize_model}
precis(m1)

m1_coef <- precis(m1)[1]
```

## Visualizing Predictions

Create a plot to show the observed data and predicted values:

```{r plot_predictions}
# Plot the observed data
plot(df$Fruit ~ df$Root, 
     col = ifelse(df$Grazing0 == 1, "red", "black"), 
     pch = ifelse(df$Grazing0 == 1, 17, 16),
     xlab = "Basal diameter (z-scores)", 
     ylab = "Fruit dry weight (z-scores)")

# Add the predicted lines
abline(a = m1_coef["a", ], b = m1_coef["b", ], col = "black", lwd = 2)
abline(a = m1_coef["a", ] + m1_coef["c", ], b = m1_coef["b", ], col = "red", lwd = 2)

# Add legend
legend("topleft", legend = c("Fenced", "Control"), col = c("red", "black"), 
       pch = c(17, 16), lty = 1, bty = "n")

```

# Adding Interactions to the Model

Interactions can model how the relationship between predictors and the response variable changes depending on the levels of other predictors. For example, we can model an interaction between soil moisture (`water`) and shade (`shade`) in the `tulips` dataset.

Prepare the data:

```{r tulips_data}
data(tulips)
tulips$blooms <- tulips$blooms / max(tulips$blooms)
tulips$water <- scale(tulips$water, scale = FALSE)
#tulips$shade <- scale(tulips$shade, scale = FALSE)
```

Fit the interaction model:

```{r fit_interaction}
m2 <- quap(
  alist(
    blooms ~ dnorm(mu, sigma),
    mu <- b0 + b1 * water + b2 * shade + b3 * water * shade,
    b0 ~ dnorm(0, 1),
    b1 ~ dnorm(0, 1),
    b2 ~ dnorm(0, 1),
    b3 ~ dnorm(0, 1),
    sigma ~ dexp(1)
  ),
  data = tulips
)
```

Summarize the interaction model:

```{r summarize_interaction}
precis(m2)
```

Visualize the interaction:

```{r visualize_interaction}
post <- extract.samples(m2)
plot(blooms ~ water, col = 2:4, pch = 16, data = tulips)
for (s in unique(tulips$shade)) {
  abline(
    a = mean(post$b0) + mean(post$b2) * s,
    b = mean(post$b1) + mean(post$b3) * s,
    col = s + 1
  )
}
legend("topright", legend = c("Shade 1", "Shade 2", "Shade 3"), col = 2:4, pch = 16)
```

# References

+ McElreath, R., 2018. Statistical Rethinking: A Bayesian Course with Examples in R and Stan, 2nd ed. CRC Press.
