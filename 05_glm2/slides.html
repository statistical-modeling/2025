<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Statistical models: linking data to theory</title>
    <meta charset="utf-8" />
    <meta name="author" content="Sara Mortara" />
    <meta name="date" content="2024-01-30" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy code <i class=\"fa fa-clipboard\"><\/i>","success":"Copied! <i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Not copied ðŸ˜• <i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="libs/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Statistical models: linking data to theory
]
.subtitle[
## The Generalized Linear Model
]
.author[
### Sara Mortara
]
.date[
### 30 Jan 2024
]

---







## Recap

* The key interest in statistical analysis is to find a meaningful relationship 
  between the __response__ variable (usually denoted by `\(y\)`) and one or 
  more __explanatory__ variables `\(x_{i}\)`

--

* In statistical modeling, minimizing __entropy__ helps derive probability 
distributions under constraints, leading to models that best represent the 
observed data


--

* __Exponential Family Distributions__ commonly used in GLMs

--

* GLM: specify a __likelihood function__

--

* GLM: use a __link function__ to connect predictors 
to the mean of the distribution

---
## Generalized Linear Models

GLMs use probability distributions from the exponential family that best fit 
the constraints defined by the predictors

--

.bg-white.b--brblack.ba.bw2.br3.shadow-5.ph4.mt1[
`$$Y_i \sim Zaphod(\theta_i, \phi)$$`
`$$f(\theta_i) = \alpha + \beta (x_i - \overline{x})$$`
]



--

- When the predictor `\(x_i\)` is mean-centered, the intercept `\(\alpha\)` represents
the value of the link function `\(f(p_i)\)` when `\(x_i\)` is at its mean
- The slope `\(\beta\)` still represents the change in `\(f(p_i)\)` for a one-unit
change in `\(x\)`

_Zaphod is not a real distribution!_ 

---
## Distributions and link functions


&lt;table class="table table-striped table-hover table-condensed" style="font-size: 22px; color: black; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Distribution &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Support &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Typical Uses &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Link Name &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Link Function &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Mean Function &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Normal &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\((-\infty, +\infty)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Linear-response data &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Identity &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = \mu\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = \mathbf{X} \boldsymbol{\beta}\)` &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Exponential &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\((0, +\infty)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Exponential-response data, scale parameters &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Negative inverse &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = -\mu^{-1}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = - (\mathbf{X} \boldsymbol{\beta})^{-1}\)` &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Gamma &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\((0, +\infty)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Various response distributions &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Inverse &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = \mu^{-1}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = (\mathbf{X} \boldsymbol{\beta})^{-1}\)` &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Poisson &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\{0,1,2,...\}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Count of occurrences in fixed time/space &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Log &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = \ln(\mu)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = \exp(\mathbf{X} \boldsymbol{\beta})\)` &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Bernoulli &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\{0,1\}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Outcome of single yes/no occurrence &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Logit &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = \ln \left(\frac{\mu}{1-\mu} \right)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = \frac{\exp(\mathbf{X} \boldsymbol{\beta})}{1 + \exp(\mathbf{X} \boldsymbol{\beta})}\)` &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Binomial &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\{0,1,...,N\}\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Count of 'yes' occurrences out of `\(N\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Logit &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = \ln \left(\frac{\mu}{N-\mu} \right)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = \frac{\exp(\mathbf{X} \boldsymbol{\beta})}{1 + \exp(\mathbf{X} \boldsymbol{\beta})}\)` &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;"&gt; Multinomial &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\([0,N]\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; K-vector of integer: `\([0, N]\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Logit &lt;/td&gt;
   &lt;td style="text-align:left;width: 6cm; "&gt; `\(\mathbf{X} \boldsymbol{\beta} = \ln \left(\frac{\mu}{1-\mu} \right)\)` &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; `\(\mu = \frac{\exp(\mathbf{X} \boldsymbol{\beta})}{1 + \exp(\mathbf{X} \boldsymbol{\beta})}\)` &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



---
## Count Data: variation from a Binomial distribution

When a binomial distribution has a very small probability of an event `\(p\)` and a
very large number of trials `\(n\)`, then it takes a special shape

.pull-left[
&lt;img src="figs/binomial.png" width="70%" style="display: block; margin: auto;" /&gt;

]

--

.pull-right[

&lt;img src="figs/binomial2.png" width="70%" style="display: block; margin: auto;" /&gt;
]


---
## Count Data: variation from a Binomial distribution



.pull-left[

![](figs/monks.jpg)&lt;!-- --&gt;


]

.pull-right[

Monastery of copying manuscripts with 1,000 monks, on average, 1 of them produce
a manuscript


``` r
# Simulate for over 10,000 days (1e5)
y &lt;- rbinom(n = 1e5, size = 1000, prob = 1/1000)
c(mean(y), var(y))
```

```
## [1] 1.0016500 0.9999773
```
]

When `\(\mu\)` and `\(\sigma^2\)` of the distribution are equal, this a special case
of a binomial a.k.a. __Poisson__

---
## Count Data: Poisson Regression

`$$Y ~ Poisson(\lambda_i)$$`
$$log(\lambda_i) = \alpha + \beta x_i $$


For response variables that are non-negative integers. For example, counting
  the number of eggs female lay as a function of their age, body size, etc. 
  You could have the number of new cases of a disease as a function
  of time. 

--

One of the assumptions of this 
  distribution is that the mean `\(\mu\)` and variance `\(\sigma^2\)` are the same and 
  expressed as `\(\lambda\)`

---
class: middle, inverse

Poisson __GLM__ with a __log__ link

---
## Poisson Regression

Defining the Poisson regression model:

$$
`\begin{align}
y_i \thicksim Poisson(\lambda)
\end{align}`
$$

--

Since `\(\lambda\)` is constrained to be positive, it is typical to use the _log_ 
  as the __link__ function. With this we are assuming that the logarithm of the
  parameter `\(\lambda_i\)` depends linearly on the predictors: 
  `\(\mathbb{E}[\lambda_i] = \mathbb{E}[log(Y_i|x_i)] = \alpha + \beta x_i\)`
The full model is:

--

$$
`\begin{align}
y_i \thicksim Poisson(\lambda) \\
log(\lambda_i) = \alpha + \beta x_i
\end{align}`
$$

The logarithm as a link function transforms the relationship between fitted 
  values and the predictors into a linear regression


---
## The Oceanic tool example


.pull-left[

+ Technological evolution in island populations


+ Tool kits of different size: fish hooks, axes, boats, hand plows... 


+ Larger populations will develop and sustain more complex tool kits


+ Oceania: natural variation in population size induced by natural variation in
island size


+ Contact rates effectively increase population size

]



.pull-right[

&lt;img src="figs/McElreath_Fig11_6.png" width="700" /&gt;
[Kline et al 2010](https://royalsocietypublishing.org/doi/10.1098/rspb.2010.0452) 
]





---
## Understanding the data and the model

$$ T_i \sim Poisson(\lambda_i)$$
$$ log(\lambda_i) = \alpha + \beta * log(P)$$


.pull-left[

- the number of tools increases with the log of population size 

- the order of magnitude is what matters

- the impact of population on total tool is moderated by __contact__ - *no nation
is an island*

- investigate a positive interaction between population and contact rate


]

.pull-right[
&lt;img src="figs/predict_poisson.png" width="70%" style="display: block; margin: auto;" /&gt;

]

---
##  Understanding the data

.pull-left[


``` r
data(Kline)
head(Kline, c(6, 4))
```

```
##      culture population contact total_tools
## 1   Malekula       1100     low          13
## 2    Tikopia       1500     low          22
## 3 Santa Cruz       3600     low          24
## 4        Yap       4791    high          43
## 5   Lau Fiji       7400    high          33
## 6  Trobriand       8000    high          19
```
]

.pull-right[


``` r
d &lt;- Kline

d$P &lt;- scale(log(d$population))
d$contact_id &lt;- ifelse(d$contact == "high", 2, 1)

dat &lt;- list(
  T = d$total_tools, 
  P = d$P, 
  cid = d$contact_id
)
```

]

---
## Build and fit the model: the __prior__


.pull-left[
$$ T_i \sim Poisson(\lambda_i)$$
$$ log(\lambda_i) = \alpha + \beta * log(P)$$
]


.pull-right[


``` r
ulam(
  alist(
    T ~ dpois(lambda), 
    log(lambda) &lt;- a + b * P, 
    a ~ dnorm(3, 0.5), 
    b ~ dnorm(0, ?)
  ), 
  data = dat, chains = 4, log_lik = TRUE
)
```
]





---
## Simulating the priors


Let's simulate curves with two different priors, one with a large variance, and
the other one with a small one


``` r
set.seed(10)
N &lt;- 100
a &lt;- rnorm(N, 3, 0.5)
b_large &lt;- rnorm(N, 0, 10)
b_small &lt;- rnorm(N, 0, 0.2)

x_seq &lt;- seq(from = log(100), to = log(200000), length.out = 100)

# given that: log(lambda) = a + b * c, then:
lambda_large &lt;- sapply(x_seq,function(x) exp(a + b_large * x))
lambda_small &lt;- sapply(x_seq,function(x) exp(a + b_small * x))
```


---
## Predicted curves based on simulated priors

&lt;img src="figs/prior_poisson.png" width="90%" style="display: block; margin: auto;" /&gt;


---
## Priors and the model fit

.pull-left[

Check the prior with `\(\sigma = 0.2\)` in the log scale

&lt;img src="figs/prior_poisson2.png" width="85%" style="display: block; margin: auto;" /&gt;
]

--

.pull-right[
Fit the model with the prior with the smallest variance

``` r
m01 &lt;- ulam(
  alist(
    T ~ dpois(lambda), 
    log(lambda) &lt;- a + b * P, 
    a ~ dnorm(3, 0.5), 
    b ~ dnorm(0, 0.2)
  ), 
  data = dat, chains = 4, log_lik = TRUE
)
```

]

---
## Comparing prior and posterior distributions


&lt;img src="figs/prior_posterior.png" width="85%" style="display: block; margin: auto;" /&gt;


---
## Model coefficients


``` r
precis(m01)
```

```
##        mean         sd      5.5%     94.5%    n_eff     Rhat4
## a 3.4800306 0.05717211 3.3881441 3.5703995 1244.732 0.9999784
## b 0.3474148 0.04734712 0.2719206 0.4256648 1289.150 1.0038322
```

``` r
coef_m01 &lt;- precis(m01)$mean

# predict the number of tools for specific population size - Hawaii
# log(lambda) = a + b * P
lambda_i &lt;- exp(coef_m01[1] + coef_m01[2] * 2.321008320)
lambda_i
```

```
## [1] 72.70305
```

``` r
Kline[Kline$culture == "Hawaii", 1:4]
```

```
##    culture population contact total_tools
## 10  Hawaii     275000     low          71
```

---
## The link function

__link()__: Apply the inverse link function to a model object and compute model
values



``` r
# create a sequence of x to use to compute lambda
P_seq &lt;- seq(from = -1.4, to = 3, length.out = 100)
lambda &lt;- link(m01, data = data.frame(P = P_seq)) 
lmu &lt;- apply(lambda, 2, mean) # mean of the simulations
head(lmu)
```

```
## [1] 20.06007 20.36861 20.68199 21.00028 21.32357 21.65192
```

``` r
lci &lt;- apply(lambda, 2, PI) # confidence intervals 
lci[, 1:7]
```

```
##         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
## 5%  16.95028 17.27975 17.60348 17.93112 18.24588 18.57589 18.90625
## 94% 23.36846 23.66311 23.96065 24.27077 24.59347 24.87902 25.22637
```


---
## Comparing predictions of model 1 with the data 

&lt;img src="figs/poisson_data_fitm01.png" width="50%" style="display: block; margin: auto;" /&gt;



---
## Interaction with contact

This means that each category of contact (i.e. low, high) would have an intercept
`\(\alpha\)` and slope `\(\beta\)`


`$$T_i \sim Poisson(\lambda_i)$$`
`$$log(\lambda_i) = \alpha_{CID[i]} + \beta_{CID[i]} * log(P)$$`

.pull-left[


``` r
m02 &lt;- ulam(
  alist(
    T ~ dpois(lambda), 
    log(lambda) &lt;- a[cid] + b[cid] * P, 
    a[cid] ~ dnorm(3, 0.5),
    b[cid] ~ dnorm(0, 0.2)
  ), 
  data = dat, chains = 4, log_lik = TRUE
)
```
]

.pull-right[

&lt;img src="figs/poisson_data2.png" width="60%" style="display: block; margin: auto;" /&gt;

]

---
## Calculating the predicted values using the link() function

__CID 1__


``` r
# predictions for cid=1 (lowcontact)
lambda1 &lt;- link(m02, data = data.frame(P = P_seq, cid = 1))
lambda1[1:5, 1:8]
```

```
##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
## [1,] 15.52966 15.78195 16.03833 16.29888 16.56367 16.83275 17.10621 17.38411
## [2,] 14.40032 14.68593 14.97719 15.27424 15.57717 15.88612 16.20119 16.52251
## [3,] 17.17734 17.51660 17.86256 18.21535 18.57511 18.94198 19.31609 19.69759
## [4,] 12.90809 13.17092 13.43911 13.71276 13.99198 14.27688 14.56759 14.86421
## [5,] 17.51200 17.81926 18.13192 18.45007 18.77379 19.10320 19.43839 19.77945
```

``` r
lmu1 &lt;- apply(lambda, 2, mean)
lci1 &lt;- apply(lambda, 2, PI)
```


---
## Calculating the predicted values using the link() function

__CID 2__



``` r
# predictions for cid=2 (highcontact)
lambda2 &lt;- link(m02, data = data.frame(P = P_seq, cid = 2))
lambda2[1:5, 1:8]
```

```
##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
## [1,] 19.74942 20.09954 20.45588 20.81853 21.18761 21.56323 21.94552 22.33458
## [2,] 40.81180 40.67587 40.54039 40.40537 40.27079 40.13666 40.00298 39.86975
## [3,] 18.70123 19.07317 19.45250 19.83938 20.23395 20.63637 21.04679 21.46537
## [4,] 27.49651 27.82654 28.16053 28.49853 28.84059 29.18675 29.53707 29.89159
## [5,] 21.37819 21.72131 22.06994 22.42416 22.78407 23.14976 23.52131 23.89883
```

``` r
lmu2 &lt;- apply(lambda2, 2, mean)
lci2 &lt;- apply(lambda2, 2, PI)
```



---
## Comparing predictions of model 2 with the data 

&lt;img src="figs/poisson_fit_m02.png" width="50%" style="display: block; margin: auto;" /&gt;


---
## Underdispersed and overdispersed data

The main feature of the Poisson distribution is that the __mean__ and the 
__variance__ are both equal to `\(\lambda\)`

--

The fact that the variance equals the mean is a hard constraint, rarely matched 
by real data

--

When you encounter over-dispersion (i.e., the variance in the data is much 
larger than what assumed by Poisson), you need to choose a different model

--

This happens very often, and one of the solutions is to use is a __Generalized 
Poisson distribution__ or alternatively __Negative Binomial Regression__ 

--

A negative binomial distribution can be thought of as a Poisson with a scaled 
variance, also called __Gamma-Poisson__ distribution


---
class: middle, inverse

A Negative Binomial regression is a special case of a __GLM__ where the response 
follows a __Negative Binomial__ distribution, modeled as a __Gamma-Poisson 
mixture__, and the __log__ function is used as the link function

---

## Poisson Model parameters

- **Poisson Distribution:** `\(Y \sim \text{Poisson}(\lambda)\)`

- The Poisson models assume the mean and variance are equal: `\(E[Y] = \text{Var}(Y) = \lambda\)`


- This assumption often fails in real-world data

--

## Gamma-Poisson Mixture

- Instead of assuming a fixed `\(\lambda\)`, model it as a 
**Gamma-distributed prior**: `\(\lambda \sim \text{Gamma}(\alpha, \beta)\)`

- The marginal distribution of `\(Y\)` becomes **Negative Binomial**: `\(Y \sim \text{NB}(r, p)\)`

- Where `\(r = \alpha\)` and `\(p = \frac{\beta}{\beta+1}\)`

---

## Why Use a Gamma Prior?

- The **Gamma distribution** is conjugate to Poisson `\(\to\)` simplifies Bayesian inference

- There is an **analytical expression** for Poisson probabilities mixed with Gamma-distributed rates

- Poisson distributions are **narrow** (variance = mean), but Gamma-Poisson allows more variation

Therefore, 

it can be used for **modeling count data** with high variance (e.g., ecological epidemiological data)

---
## The distribution of Negative-Binomial or Gamma-Poisson

&lt;img src="slides_files/figure-html/unnamed-chunk-24-1.png" style="display: block; margin: auto;" /&gt;

---
## Fitting a  Negative-Binomial or Gamma-Poisson model 

- A **Negative Binomial model** is also known as a **Gamma-Poisson model**

- It assumes each **Poisson count observation has its own rate**

- This model estimates the **shape of a Gamma distribution** to describe Poisson rates

- Predictor variables **adjust the shape of the distribution, not the expected value** of each observation

---
## Back to the ocean islands example

$$ Y_i âˆ¼ Gamma-Poisson(\lambda_i, \phi)$$

- __ `\(\lambda\)` __ is the __rate__ parameter

- __ `\(\phi\)` __ is a positive parameter that controls for __variance__

- The variance is: `\(\lambda + \lambda^2/\phi\)`

- __Larger `\(\phi\)`__ means the distribution
is closer to a __pure Poisson process__

---
## Building the model

$$ Y_i âˆ¼ Gamma-Poisson(\lambda_i, \phi)$$

The standard approach in __log-link__ Poisson regression is:

`$$\log(\lambda) = \alpha_{CID[i]} + \beta_{CID[i]} * log(P)$$`

In this model, an additional scaling factor `\(g\)` is introduced:

`$$\log(\lambda) = \alpha_{CID[i]} + \beta_{CID[i]} * log(P) - log(g)$$`

This represents a __global normalization__ to prevent uncontrolled growth

---
## Where does __g__ come from?

- Poisson Model: assumes a __fixed `\(\lambda\)`__

- Gamma-Poisson Model: Instead of a fixed `\(\lambda\)`, assume it follows a __Gamma prior__:

`$$\lambda \sim Gamma(\alpha, 1/g)$$`

- `\(g\)` acts as a __scaling factor__ controlling dispersion 

- This prior introduces extra variance, leading to a __Negative Binomial__ marginal 
distribution

Thus:

- `\(\lambda\)` is modeled as a hierarchical function of population size
- The global scale parameter `\(g\)` accounts for extra variability in the Poisson process
- Higher `\(g\)` means higher variance, ensuring the model can account for overdispersion


---
## Understanding the model notation

`$$\log(\lambda) = \alpha_{CID[i]} + \beta_{CID[i]} * log(P) - log(g)$$`

This is also:

`$$\lambda = exp(\alpha_{CID[i]} + \beta_{CID[i]} * log(P) - log(g))$$`

Using log rules:

`$$\lambda = \frac{exp(\alpha_{CID[i]}) P^{\beta_{CID[i]}}}{g}$$`

This formulation arises because:

- `\(g\)` comes from the Gamma prior, influencing the variance
- The log transformation ensures `\(\lambda\)` stays positive
- The power-law effect of `\(P\)` enables nonlinear scaling in response predictions


---
## Building the model in R





.pull-left[


``` r
# The previous model:
m02 &lt;- ulam(
  alist(
    T ~ dpois(lambda), 
    log(lambda) &lt;- a[cid] + b[cid] * P, 
    a[cid] ~ dnorm(3, 0.5),
    b[cid] ~ dnorm(0, 0.2)
  ), 
  data = dat, chains = 4, log_lik = TRUE
)
```

]


.pull-right[

``` r
# Creating a dataset
dat2 &lt;-list(
  T = d$total_tools,
  P = d$population, # no log transformation
  cid = d$contact_id)

# Gamma-poisson model with the scalling factor g
m3 &lt;- ulam(
  alist(
    T ~ dgampois(lambda, phi),
    lambda &lt;- exp(a[cid]) * P ^ b[cid] / g,
    a[cid] ~ dnorm(1, 1),
    b[cid] ~ dexp(1),
    g ~ dexp(1),
    phi ~ dexp(1)
  ),
  data = dat2,
  chains = 4,
  log_lik = TRUE
)
```
]



---
## Comparing predictions of model 3 with the data 

&lt;img src="figs/model03.png" width="80%" style="display: block; margin: auto;" /&gt;


---

## Conclusion

- The **Negative Binomial** arises naturally from a **Gamma-Poisson** process

- Useful for **modeling overdispersion** in count data

- Widely used in **Bayesian statistics and hierarchical modeling**

- Easy to implement in **R, Stan, JAGS, and other Bayesian frameworks**

---

## Take home messages

- The choice of probability distribution for `\(Y\)` follows the principle of 
__maximum entropy__ under given constraints

--

- __Link functions__ transform nonlinear relationships into linear ones, making 
model interpretation more intuitive

--

- __Generalized Linear Models__ (GLMs) extend classical regression to handle 
different types of response variables (counts, binary outcomes, etc.)

--

- Overdispersion matters! When variance exceeds the mean, Negative Binomial 
models provide a better fit than Poisson

-- 
- Bayesian approaches allow flexible modeling of LMs, GLMs, and mixture models 
using a unified conceptual framework


---
## Further reading

+ Generalized linear models with examples in R (Vol. 53). 
  Dunn, P. K., &amp; Smyth, G. K. (2018) New York: Springer.

+ "Regression models for count data in R." Zeileis, Achim, Christian Kleiber, 
  and Simon Jackman. Journal of statistical software 27.8 (2008): 1-25.
  
+ "Statistical modeling of patterns in annual reproductive rates."
  Brooks, Mollie E., et al. Ecology 100.7 (2019): e02706.
  
  
+ Statistical Rethinking, chapters 11 and 12
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
