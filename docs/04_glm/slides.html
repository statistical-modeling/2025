<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Statistical models: linking data to theory</title>
    <meta charset="utf-8" />
    <meta name="author" content="Sara Mortara" />
    <meta name="date" content="2025-01-28" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy code <i class=\"fa fa-clipboard\"><\/i>","success":"Copied! <i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Not copied ðŸ˜• <i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="libs/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Statistical models: linking data to theory
]
.subtitle[
## The Generalized Linear Model
]
.author[
### Sara Mortara
]
.date[
### 28 Jan 2025
]

---







## Recap

* The key interest in statistical analysis is to find a meaningful relationship 
  between the __response__ variable (usually denoted by `\(y\)`) and one or 
  more __explanatory__ variables `\(x_{i}\)`

--

* So far we have assumed the response variable `\(y\)` changes continuously and 
  errors are normally distributed around the mean, but this need not be the case


--

* The most extreme deviation of normality is when your response variable can 
  only assume `\(0\)` or `\(1\)` values (binary data)

--

* Other deviations include categorical variables and count data and for these 
  cases as well as situations that do not conform to some of the assumptions of 
  a linear model we use generalized linear models



---
## Rethinking gaussian linear regression
### Maximum Entropy

__Definition__: The probability distribution with the largest entropy is the one
that makes the fewest assumptions about the data, given constraints

- Bet on the distribution with the biggest entropy

- The center of gravity for high plausible distributions

--
  
$$ 
`\begin{align}
H(p) = -\sum{p_{i} log p_{i}}
\end{align}`
$$ 
&gt; The distribution that can happen the __most ways__ is also the distribution with 
the biggest information theory. The distribution with the biggest entropy is the
__most conservative__ distribution that obeys its constraints.

Richard McElreath


---
## Understanding entropy

.pull-left[
&lt;img src="figs/McElreath_Fig10_1.png" width="80%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
How can pebbles be distributed across buckets under varying constraints?

- `\(\uparrow\)` entropy as we increase the N of buckets

- `\(\uparrow\)` entropy as we even the distribution of pebbles

- E: distribution that can happen the __most ways__

- E: __most conservative__ distribution that obeys its constraints

]

---
## Generalized linear models 


Choose the probability distribution from the __exponential family__ that best 
matches the constraints imposed by the predictors


&lt;img src="figs/McElreath_Fig10_6.png" width="40%" style="display: block; margin: auto;" /&gt;


---
## Discrete and continuous distributions


.pull-left[
__Discrete__: Binomial distribution

&lt;img src="figs/discrete.png" width="90%" /&gt;
]


.pull-right[
__Continuous__: Exponential distribution

&lt;img src="figs/continuous.png" width="90%" /&gt;
]

---
## Exponential family of distributions: Exponential
### `\(Y \sim Exponential(\lambda)\)`

.pull-left[

- The Exponential distribution models the __time between events__ in a process that 
occurs continuously and independently at a constant rate `\(\lambda\)`

- Rate parameter: `\(\lambda\)`

- The mean of the distribution is `\(1 / \lambda\)`

- Common applications: Failure times of systems, waiting times in queues

]

.pull-right[
.center[
&lt;img src="figs/exponential.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]

---
## Exponential family of distributions: Gamma
### `\(Y \sim Gamma(\lambda, k)\)`

.pull-left[

+ The Gamma generalizes the Exponential distribution by adding flexibility with two parameters: `\(\lambda\)` (rate) and `\(k\)` (shape)

+ The mean is `\(\mu = k / \lambda\)`, and the variance is `\(\sigma^2 = k / \lambda^2\)`

+ Common applications: Modeling lifetimes of processes with additional variability

]

.pull-right[
.center[
&lt;img src="figs/gamma.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]


---
## Exponential family of distributions: Normal
### `\(Y \sim Normal(\mu, \sigma)\)`


.pull-left[


* The Normal has a **location parameter**, that we will call `\(\mu\)`

* This parameter corresponds to the mean of the Normal distribution

* By changing `\(\mu\)` we change the position of the Normal distribution
along the x axis, without changing the standard deviation
]

.pull-right[
.center[
&lt;img src="figs/normal_mu.png" width="3436" style="display: block; margin: auto;" /&gt;
]
]


---
## Exponential family of distributions: Normal
### `\(Y \sim Normal(\mu, \sigma)\)`



.pull-left[
* The Normal has a **scale parameter**, that we will call `\(\sigma\)`

* This parameter corresponds to the standard deviation of the Normal distribution

* By changing `\(\sigma\)` we change the spread of the Normal distribution
around the mean, without changing the mean

]

.pull-right[
.center[
&lt;img src="figs/normal_sigma.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]


---
## Exponential family of distributions: Poisson
### `\(Y \sim Poisson(\lambda)\)`

.pull-left[

+ The Poisson distribution models the number of events that occur in a fixed interval of time or space


+ `\(\lambda\)`: the average rate of events in the interval

+ The mean and variance are both equal to `\(\lambda\)`

+ Common applications: Counting rare events such species number

]

.pull-right[
.center[
&lt;img src="figs/poisson.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]

---
## Exponential family of distributions: Binomial
### `\(Y \sim Binomial(n, p)\)`

.pull-left[

+ The Binomial distribution models the __number of successes__ in `\(n\)` independent trials of an experiment with success probability `\(p\)`

+ The mean is `\(np\)`, and the variance is `\(np(1-p)\)`

+ Common applications: Success/failure experiments such as coin flips or clinical trials

]

.pull-right[
.center[
&lt;img src="figs/binomial.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]


---
## Generalized Linear Models

GLMs choose the probability distribution from the exponential family that best 
matches the constraints imposed by the predictors


.bg-white.b--brblack.ba.bw2.br3.shadow-5.ph4.mt1[
`$$Y_i \sim Normal(\mu, \sigma) \\
\mu_i = \alpha + \beta x_i$$`
]

--

.bg-white.b--brblack.ba.bw2.br3.shadow-5.ph4.mt1[
`$$Y_i \sim Binomial(n, p_i) \\
f(p_i) = \alpha + \beta (x_i - \overline{x})$$`
]


--
- When the predictor `\(x_i\)` is mean-centered, the intercept `\(\alpha\)` represents
the value of the link function `\(f(p_i)\)` when `\(x_i\)` is at its mean
- The slope `\(\beta\)` still represents the change in `\(f(p_i)\)` for a one-unit
change in `\(x\)`
 



---
## Generalized Linear Models

* The response variable is modeled by a distribution from the exponential family
  (e.g. Gaussian, Gamma, Binomial, Poisson)

--

* Independent variables (or covariates) may be continuous, categorical
  or a combination of both

--

* The link function linearizes the relationship between fitted values and the 
  predictors

--

* Parameters are estimated through least squares algorithm

---

## Model Structure

We need to determine three parts of the model:

* __Random component__ entries of the response variable `\(Y\)` are assumed to be 
  independently drawn from a distribution of the exponential family 
  (e.g. Binomial). It models the variation of the data about the mean
  
  
$$
`\begin{align}
y_i \sim \mathcal{Binomial}(n, p_i) \\
\mathcal{logit}(p_i) = \alpha + \beta x_i \\
\end{align}`
$$
---

## Model Structure

We need to determine three parts of the model:

* __Random component__ entries of the response variable `\(Y\)` are assumed to be 
  independently drawn from a distribution of the exponential family 
  (e.g. Poisson). It models the variation of the data about the mean

* __Systematic component__ explanatory variables `\(\left( x_1, x_2, \dots \right)\)` 
  are combined linearly to form a linear prediction 
  (e.g: `\(\alpha + \beta_1 x_1 + \beta_2 x_2 + \dots\)`). We want to know how the 
  mean response changes as the explanatory variables change

--

* __Link function__ `\(f(p)\)` specifies how the random and systematic components 
  are connected

---

## A GLM consists of 3 steps

1. Choose the __distribution__ for the response variable:

  This choice should be made a priori based on available knowledge on the 
  response variable

--

2. Define the __systematic__ part in terms of covariates

--

3. Specify the relationship (__link__) between the expected value of the response
  variable and the systematic part


---

## Binary Data

*-* It's an extreme departure from normality. Response variable assumes only 
values `\(1\)` or `\(0\)` (no/yes, survived/deceased, presence/absence, lost/won)

--

A Bernoulli random variable can only assume values `\(1\)` or `\(0\)` and therefore 
provides the __random component__ of the model. The Bernoulli distribution is a
special case of the __Binomial distribution__ and can be expressed as:

$$
`\begin{align}
P(Y_i = y_i | p_i) = p_i^{y_i} (1-p_i)^{1-y_i}
\end{align}`
$$
--

Saying that the probability `\(P(Y_i = 1) = \pi_i\)` and `\(P(Y_i = 0) = (1-p_i)\)`

--

Now we want to relate the parameter `\(p_i\)` to the __linear predictor__
  `\(\left( x\right)\)` choosing a __link function__

---

## Logistic Regression

The most popular choice is to use the _Logit_ function as the link function

--

The basic Binomial (Logistic) Regression follows the form:

$$
`\begin{align}
y_i \thicksim Binomial(n, p_i) \\[1em]
logit(p_i) = \alpha + \beta x_i
\end{align}`
$$

where `\(y\)` is some count variable, `\(n\)` is the number of trials, and `\(\pi\)` is the 
probability a given trial was `\(1\)`. In our binary example, `\(n=1\)` which means `\(y\)` 
will be a vector of 1's and 0's.

--

Now let's take a closer look at our link function

$$
`\begin{align}
logit(p_i) = \alpha + \beta x_i
\end{align}`
$$

---

## Logistic Regression

The function `\(Logit(\pi_i) = \alpha + \beta x_i\)` can be written as:

$$
`\begin{align}
Logit(p_i) = \log\left(\frac{p_i}{(1-p_i)}\right)    
\end{align}`
$$
--

Practically this means:

$$
`\begin{align}
p_i = \frac{e^{\alpha + \beta x_i}}{1+e^{\alpha + \beta x_i}}
\end{align}`
$$
--

when `\(\alpha + \beta x_i = 0\)` the probability `\(p_i = \frac{1}{2}\)`

while the probability tends to one when `\(\alpha + \beta x_i \to \infty\)` and 
  zero when `\(\alpha + \beta x_i \to - \infty\)`

---

## Logistic Regression

Now let's see how this looks like

.pull-left[

] 

--

.pull-right[
![](slides_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;
]

---

## Logistic Regression

Now let's see how this looks like

.pull-left[

```r
set.seed(123)
# some random data
X &lt;- rnorm(100)
alpha &lt;- 0.35
beta &lt;- -3.2

linear_predictor &lt;- alpha + beta * X
predicted_pi_i &lt;- exp(linear_predictor) / 
                (1 + exp(linear_predictor))
```

This is a logistic curve. The parameters `\(\alpha\)` and `\(\beta\)`
  control the location of the inflection point and the steepness of the curve, 
  allowing you to model binary response variables

]

.pull-right[
![](slides_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;
]

---
## The Titanic example

.pull-left[

&lt;img src="figs/titanic.jpg" width="1971" style="display: block; margin: auto;" /&gt;

]

.pull-right[

```r
data("Titanic")
Titanic[, , Age = "Child", ]
```

```
## , , Survived = No
## 
##       Sex
## Class  Male Female
##   1st     0      0
##   2nd     0      0
##   3rd    35     17
##   Crew    0      0
## 
## , , Survived = Yes
## 
##       Sex
## Class  Male Female
##   1st     5      1
##   2nd    11     13
##   3rd    13     14
##   Crew    0      0
```
]



---
## The Titanic example


Let's model the probability of survival according to class and gender. We can 
  start with a null model where we assume all passengers have the same 
  probability of survival
  
  `$$y_i \sim Binomial(n, p_i)$$`
  
  `$$logit(p_i) = \alpha$$`
  
--



```r
library(titanic)

# Data preparation
df &lt;- data.frame(survived = titanic_train$Survived)

# Bayesian Null Model
model_null &lt;- quap(
  alist(
    survived ~ dbinom(1, p),  # Likelihood
    logit(p) &lt;- a,            # Linear model
    a ~ dnorm(0, 1)           # Prior for intercept
  ),
  data = list(survived = df$survived, n = nrow(df))
)
```



---
## The Titanic example: the null model


$$
`\begin{align}
p_i = \frac{e^{\alpha + \beta x_i}}{1+e^{\alpha + \beta x_i}}
\end{align}`
$$



```r
# Summary
m0_precis &lt;- precis(model_null, prob = 0.95)
# the best fitting (alpha) intercept should lead to 
# e^alpha / (1 + e^alpha) = mean(Survived)
alpha &lt;- m0_precis$mean
exp(alpha) / (1 + exp(alpha))
```

```
## [1] 0.3843787
```

```r
mean(titanic_train$Survived)
```

```
## [1] 0.3838384
```



---
## The Titanic example: the effect of gender

Now let's include gender. What was the probability of surviving depending on gender?


`$$y_i \sim Binomial(n, p_i)$$`
`$$logit(p_i) = \alpha + \beta * Gender$$`
  
--


```r
# Convert gender to numeric
df$gender &lt;- as.numeric(titanic_train$Sex == "male")

# Bayesian Model with Gender
model_gender &lt;- quap(
  alist(
    survived ~ dbinom(1, p),          # Likelihood
    logit(p) &lt;- a + b * gender,       # Linear model
    a ~ dnorm(0, 1),                  # Prior for intercept
    b ~ dnorm(0, 1)                   # Prior for slope
  ),
  data = list(survived = df$survived, gender = df$gender)
)
```


---
## The Titanic example: the effect of gender

Now let's include gender. What was the probability of surviving depending on gender?


`$$y_i \sim Binomial(n, p_i)$$`

`$$logit(p_i) = \alpha + \beta * Gender$$`
  
--


```r
# Summary
precis(model_gender, prob = 0.95)
```

```
##        mean        sd       2.5%     97.5%
## a  1.000278 0.1252771  0.7547399  1.245817
## b -2.430143 0.1623292 -2.7483023 -2.111983
```



---
## The Titanic example: the effect of gender


$$ p = \frac{1}{1 + e^{-logit(p)}}$$ 

The calculation `\(\frac{1}{1 + odds}\)` converts odds to probabilities


```r
# What is the best-fitting probability of 
 # survival for male/female?
coeffs &lt;- precis(model_gender)

# Probability of survival for women
1 - 1 / (1 + exp(coeffs['a', 'mean']))
```

```
## [1] 0.7311133
```

```r
# Probability of survival for men
1 - 1 / (1 + exp(coeffs['a', 'mean'] + coeffs['b', 'mean']))
```

```
## [1] 0.1931198
```

---
## The Titanic example: the effect of gender and class

Our data set also includes information on passenger's class. Let's incorporate 
  that into our model


`$$logit(p_i) = \alpha + \beta_1 * Sex + \beta_2 * Class$$`



```r
# Prepare class data
df$class &lt;- as.factor(titanic_train$Pclass)

# Bayesian Model with Gender and Class using quap
model_class &lt;- quap(
  alist(
    survived ~ dbinom(1, p),                      # Likelihood
    logit(p) &lt;- a + b_1 * gender + b_2[class],  # Linear model
    a ~ dnorm(0, 1),                              # Prior for intercept
    b_1 ~ dnorm(0, 1),                       # Prior for gender slope
    b_2[class] ~ dnorm(0, 1)              # Prior for class effects
  ),
  data = list(
    survived = df$survived,
    gender = df$gender,
    class = df$class
  )
)

# Summary
precis(model_class, depth = 2, prob = 0.95)
```

```
##              mean        sd        2.5%      97.5%
## a       0.9750795 0.5110585 -0.02657676  1.9767357
## b_1    -2.5283617 0.1763667 -2.87403415 -2.1826892
## b_2[1]  1.2013772 0.5196690  0.18284467  2.2199097
## b_2[2]  0.4008716 0.5199295 -0.61817146  1.4199147
## b_2[3] -0.6271755 0.5116857 -1.63006114  0.3757101
```


---
## The Titanic example: the effect of gender and class



```r
(coeffs &lt;- precis(model_class, depth = 2))
```

```
##              mean        sd       5.5%      94.5%
## a       0.9750795 0.5110585  0.1583093  1.7918497
## b_1    -2.5283617 0.1763667 -2.8102298 -2.2464936
## b_2[1]  1.2013772 0.5196690  0.3708458  2.0319086
## b_2[2]  0.4008716 0.5199295 -0.4300761  1.2318194
## b_2[3] -0.6271755 0.5116857 -1.4449482  0.1905971
```

```r
# A woman in first class
as.numeric(1 - 1 / (1 + exp(coeffs['a', 'mean'] + coeffs['b_2[1]', 'mean'])))
```

```
## [1] 0.8981153
```

```r
# A man in third class
as.numeric(1 - 1 / (1 + exp(coeffs['a', 'mean'] + 
                              coeffs['b_1', 'mean'] + 
                              coeffs['b_2[3]', 'mean'])))
```

```
## [1] 0.1015192
```

---
## Comparing estimates with the data


```r
library(dplyr)
titanic_train %&gt;% 
  group_by(Sex, Pclass) %&gt;% 
  summarize(p = mean(Survived))
```

```
## # A tibble: 6 Ã— 3
## # Groups:   Sex [2]
##   Sex    Pclass     p
##   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;
## 1 female      1 0.968
## 2 female      2 0.921
## 3 female      3 0.5  
## 4 male        1 0.369
## 5 male        2 0.157
## 6 male        3 0.135
```



---
## Further reading

+ Generalized linear models with examples in R (Vol. 53). 
  Dunn, P. K., &amp; Smyth, G. K. (2018) New York: Springer.

+ "Regression models for count data in R." Zeileis, Achim, Christian Kleiber, 
  and Simon Jackman. Journal of statistical software 27.8 (2008): 1-25.
  
+ "Statistical modeling of patterns in annual reproductive rates."
  Brooks, Mollie E., et al. Ecology 100.7 (2019): e02706.
  
+ Generalized linear models. Chapter 10 in McElreath. Statistical rethinking. 
  Boca Ratol, FL, CRC Press.Statistical rethinking. 
  
  
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
